# type: ignore  # Prevent issues with auto-linting snakefiles
"""This snakefile generates and executes .apsimx simulations given geojson regions and some simulation parameters"""

import os.path as op
from pathlib import Path

from snakefile_helpers import build_apsim_execution_command, get_evaluation_results_path_func

rule all:
    params:
        roi_name = config['roi_name']
    input:
        #sim_match_output_fpath = expand(op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_sim_matches.csv'), year=config['years'], region=config['regions'], timepoint=config['timepoints']),
        sim_match_report_html_fpath = expand(op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_yield_report.html'), year=config['years'], region=config['regions'], timepoint=config['timepoints']),
        sim_match_report_png_fpath = expand(op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_yield_report.png'),  year=config['years'], region=config['regions'], timepoint=config['timepoints']),
        #converted_lai_map = expand(op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_yield_map.tif'), year=config['years'], region=config['regions'], timepoint=config['timepoints']),
        #sim_match_report_logs = expand('logs_match_sim_real_quicklook/{year}_{timepoint}_{region}.log', year=config['years'], region=config['regions'], timepoint=config['timepoints']),
        #total_yield_csv = expand(op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_converted_map_yield_estimate.csv'), year=config['years'], region=config['regions'], timepoint=config['timepoints']),
        aggregated_yield_estimates = expand(op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'aggregated_yield_estimates_{}_{}_{}_{}.csv'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')), year=config['years'], timepoint=config['timepoints']),
        aggregated_yield_map = expand(op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'aggregated_yield_map_{}_{}_{}_{}.tif'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')), year=config['years'], timepoint=config['timepoints']),
        final_report = expand(op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'final_report_{}_{}_{}_{}.pdf'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')), year=config['years'], timepoint=config['timepoints']),
        met_stats = expand(op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'aggregated_met_stats_{}_{}_{}_{}.pdf'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')), year=config['years'], timepoint=config['timepoints']),


#######################################
# APSIM Section of Snakemake pipeline

# Rule to hit NASA POWER's API to get weather data and save as CSV
rule fetch_met_data:
    input:
        op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}.geojson')
    params:
        nasa_power_start_date = lambda wildcards: config['apsim_params'][int(wildcards.year)][wildcards.timepoint]['nasa_power_start_date'],
        nasa_power_end_date = lambda wildcards: config['apsim_params'][int(wildcards.year)][wildcards.timepoint]['nasa_power_end_date'],
        script_fpath = config['scripts']['fetch_met_data'],
        head_dir = config['sim_study_head_dir'],
        jq_load_statement = 'module load jq' if config['platform'] == 'umd' else ''
    log: 
        'logs_match_sim_real/{year}_{timepoint}_{region}.log',
    output:
        csv = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_nasapower.csv'),
    threads: workflow.cores * 0.75  # Set this high as to limit parallelization here. Don't want to hit NASA servers too fast and be blacklisted
    shell:
        """
        {params.jq_load_statement}
        read LON LAT <<< $(cat {input}  | jq -r '.features[].properties.centroid' | awk '{{gsub(/POINT \(/, ""); gsub(/\)/, ""); print $1, $2}}')

        python {params.script_fpath} \
        --start_date {params.nasa_power_start_date} \
        --end_date {params.nasa_power_end_date} \
        --variables ALLSKY_SFC_SW_DWN \
        --variables T2M_MAX \
        --variables T2M_MIN \
        --variables T2M \
        --variables PRECTOTCORR \
        --variables WS2M \
        --lon ${{LON}} \
        --lat ${{LAT}} \
        --output_dir {params.head_dir}/{wildcards.year}/{wildcards.timepoint}/{wildcards.region}/ \
        --overwrite \
        --verbose > {log}
        """

# Rule to generate .met files from weather CSVs
rule construct_plot_met_files:
    input:
        csv = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_nasapower.csv'),
        geojson = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}.geojson'),
    params:
        met_gen_script_fpath = config['scripts']['construct_met_files'],
        met_plot_script_fpath = config['scripts']['plot_met_files'],
        head_dir = config['sim_study_head_dir'],
        sim_end_date = lambda wildcards: config['apsim_params'][int(wildcards.year)][wildcards.timepoint]['sim_end_date'],
    log:
        'logs_construct_plot_met_files/{year}_{timepoint}_{region}.log',
    output:
        met_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_weather.met'),
        plot_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_weather_report.html'),
    shell:
        """
        read LON LAT <<< $(cat {input.geojson}  | jq -r '.features[].properties.centroid' | awk '{{gsub(/POINT \(/, ""); gsub(/\)/, ""); print $1, $2}}')

        python {params.met_gen_script_fpath} \
        --weather_data_fpath {input.csv} \
        --lon ${{LON}} \
        --lat ${{LAT}} \
        --sim_end_date {params.sim_end_date} \
        --output_dir {params.head_dir}/{wildcards.year}/{wildcards.timepoint}/{wildcards.region} \
        --verbose > {log}
        
        python {params.met_plot_script_fpath} \
        --input_fpath {output.met_fpath} \
        --output_fpath {output.plot_fpath} > {log}
        """
        

# Rule to sub in the .met files to a .apsimx simulation template
rule update_apsimx_template:
    input:
        met_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_weather.met'),
        met_plot_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_weather_report.html'),
    params:
        script_fpath = config['scripts']['update_apsimx_template'],
        head_dir = config['sim_study_head_dir'],
        sim_end_date = lambda wildcards: config['apsim_params'][int(wildcards.year)][wildcards.timepoint]['sim_end_date']
    log:
        'logs_update_apsimx_template/{year}_{timepoint}_{region}.log',
    output:
        apsimx_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}.apsimx')
    shell:
        """
        python {params.script_fpath} \
        --apsimx_template_fpath {params.head_dir}/{wildcards.year}/{wildcards.timepoint}/{wildcards.region}/{wildcards.region}_template.apsimx \
        --apsimx_output_fpath {output.apsimx_fpath} \
        --new_met_fpath {input.met_fpath} \
        --verbose > {log}
        """

# Rule to run the APSIM executable either with docker or local executable on .apsimx files
rule execute_simulations:
    input:
        op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}.apsimx'),
    params:
        head_dir = config['sim_study_head_dir'],
        use_docker =  config['apsim_execution']['use_docker'],
        execution_command = lambda wildcards, input: build_apsim_execution_command(
            config['sim_study_head_dir'],
            config['apsim_execution']['use_docker'],
            config['apsim_execution']['docker']['image'],
            config['apsim_execution']['docker']['platform'],
            config['apsim_execution']['local']['executable_fpath'],
            config['apsim_execution']['local']['n_jobs'],
            input)
    log:
        'logs_execute_simulation/{year}_{timepoint}_{region}.log',
    output:
        db_file = (
            op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}.db')
            if config['keep_apsim_db_files']
            else temp(op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}.db'))
        )
    retries: 2 if not config['apsim_execution']['use_docker'] else 5  # Docker image has habit of failing sometimes
    benchmark:
        "benchmarks/execute_simulations_{year}_{timepoint}_{region}.txt"
    shell:
        """
        {params.execution_command} --verbose > {log}
        """

#######################################
# S2/LAI portion of Snakemake pipeline


# Clip the original cropmask
rule constrain_lai_cropmask:
    input:
        original_lai_cropmask = lambda wildcards: config['lai_params']['crop_mask'][int(wildcards.year)],  # Will need to update to time period
        geometry_path = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}.geojson'),
    params:
        executable_fpath = config['scripts']['constrain_lai_cropmask'],
    log:
        'logs_constrain_lai_cropmask/{year}_{timepoint}_{region}.log'
    output:
        constrained_cropmask = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_cropmask_constrained.tif'),
    shell:
        """
        python {params.executable_fpath} \
        {input.original_lai_cropmask} \
        {input.geometry_path} \
        {output.constrained_cropmask} > {log}
        """

# Run LAI analysis to extract LAI stats and max image
rule lai_analysis:
    input:
        constrained_cropmask = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_cropmask_constrained.tif')
    params:
        executable_fpath = config['scripts']['lai_analysis'],
        lai_dir = config['lai_params']['lai_dir'],
        lai_region = config['lai_params']['lai_region'],
        lai_resolution = config['lai_params']['lai_resolution'],
        mode = config['lai_params']['lai_analysis_mode'],
        adjustment = config['lai_params']['crop_name'] if config['lai_params']['use_crop_adjusted_lai'] else "none",
        start_date = lambda wildcards: config['lai_params']['time_bounds'][int(wildcards.year)][wildcards.timepoint][0],
        end_date = lambda wildcards: config['lai_params']['time_bounds'][int(wildcards.year)][wildcards.timepoint][1],
    benchmark:
        "benchmarks/lai_analysis_{year}_{timepoint}_{region}.txt"
    log:
        'logs_lai_analysis/{year}_{timepoint}_{region}.log'
    output:
        stats_csv = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_LAI_STATS.csv'),
        max_lai_tif = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_LAI_MAX.tif'),
    shell:
        """
        python {params.executable_fpath} \
        {params.lai_dir} \
        {output.stats_csv} \
        {output.max_lai_tif} \
        {params.lai_region} \
        {params.lai_resolution} \
        {input.constrained_cropmask} \
        --mode {params.mode} \
        --adjustment {params.adjustment} \
        --start_date {params.start_date} \
        --end_date {params.end_date} > {log}
        """

rule lai_quicklook:
    input:
        stats_csv = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_LAI_STATS.csv'),
        max_lai_tif = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_LAI_MAX.tif'),
    params:
        executable_fpath = config['scripts']['lai_quicklook'],
    log:
        'logs_lai_quicklook/{year}_{timepoint}_{region}.log',
    output:
        output_png = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_LAI_QUICKLOOK.tif'),
    shell:
        """
        python {params.executable_fpath} \
        {input.stats_csv} \
        {input.max_lai_tif} > {log}
        """

#######################################
# Match sim/real (APSIM/S2-LAI) outputs

rule match_sim_real:
    input:
        stats_csv = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_LAI_STATS.csv'),
        db_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}.db'),
    params:
        executable_fpath = config['scripts']['match_sim_real'],
        adjustment = "--use_adjusted" if config['lai_params']['use_crop_adjusted_lai'] else "",
        crop_name = config['lai_params']['crop_name'],
    log:
        'logs_match_sim_real/{year}_{timepoint}_{region}.log',
    output:
        sim_matches_output_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_sim_matches.csv'),
        conversion_factor_output_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_conversion_factor.csv'),
    shell:
        """
        python {params.executable_fpath} \
        --rs_lai_csv {input.stats_csv} \
        --db_path {input.db_fpath} \
        --sim_matches_output_fpath {output.sim_matches_output_fpath} \
        --conversion_factor_output_fpath {output.conversion_factor_output_fpath} \
        --crop_name {params.crop_name} \
        {params.adjustment} \
        --verbose > {log}
        """

rule generate_converted_lai_map:
    input:
        max_lai_tif = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_LAI_MAX.tif'),
        conversion_factor_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_conversion_factor.csv'),
    params:
        executable_fpath = config['scripts']['generate_converted_lai_map'],
        adjustment = "--use_adjusted" if config['lai_params']['use_crop_adjusted_lai'] else "",  # Tells us to use first band (unadjusted) or second band (adjusted)
    log:
        'logs_generate_converted_lai_map/{year}_{timepoint}_{region}.log',
    output:
        converted_lai_map = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_yield_map.tif'),
    shell:
        """
        python {params.executable_fpath} \
        --tif_fpath {input.max_lai_tif} \
        --csv_fpath {input.conversion_factor_fpath} \
        --output_tif_fpath {output.converted_lai_map} \
        {params.adjustment} \
        --verbose > {log}
        """

rule estimate_total_yield:
    input:
        converted_lai_map = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_yield_map.tif'),
    params:
        executable_fpath = config['scripts']['estimate_total_yield'],
        target_epsg = lambda wildcards: config['matching_params']['target_epsgs'][wildcards.region],
    log:
        'logs_estimate_total_yield/{year}_{timepoint}_{region}.log',
    output:
        total_yield_csv = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_converted_map_yield_estimate.csv'),
    shell:
        """
        python {params.executable_fpath} \
        --converted_lai_tif_fpath {input.converted_lai_map} \
        --target_epsg {params.target_epsg} \
        --output_yield_csv_fpath {output.total_yield_csv} \
        --verbose > {log}
        """


rule match_sim_real_quicklook:
    input:
        sim_matches_output_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_sim_matches.csv'),
        rs_stats_csv_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_LAI_STATS.csv'),
        apsim_db_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}.db'),
        total_yield_csv_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_converted_map_yield_estimate.csv'),
    params:
        executable_fpath = config['scripts']['match_sim_real_quicklook'],
        crop_name = config['lai_params']['crop_name'],
    log:
        'logs_match_sim_real_quicklook/{year}_{timepoint}_{region}.log',
    output:
        html_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_yield_report.html'),
        png_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', '{region}', '{region}_yield_report.png'),
    shell:
        """
        python {params.executable_fpath} \
        --apsim_filtered_fpath {input.sim_matches_output_fpath} \
        --rs_lai_csv_fpath {input.rs_stats_csv_fpath} \
        --apsim_db_fpath {input.apsim_db_fpath} \
        --crop_name {params.crop_name} \
        --total_yield_csv_fpath {input.total_yield_csv_fpath} \
        --html_fpath {output.html_fpath} \
        --png_fpath {output.png_fpath} > {log}
        """

rule aggregate_yield_estimates:
    input:
        total_yield_csvs = expand(op.join(config['sim_study_head_dir'], '{{year}}', '{{timepoint}}', '{region}', '{region}_converted_map_yield_estimate.csv'), region=config['regions']),
        conversion_factor_fpath =  expand(op.join(config['sim_study_head_dir'], '{{year}}', '{{timepoint}}', '{region}', '{region}_conversion_factor.csv'), region=config['regions'])
    params:
        executable_fpath = config['scripts']['aggregate_yield_estimates'],
        yield_dir = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}')
    log:
        'logs_aggregate_yield_estimates/{year}_{timepoint}.log'
    output:
        aggregated_csv = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'aggregated_yield_estimates_{}_{}_{}_{}.csv'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')),
    shell:
        """
        python {params.executable_fpath} \
        --yield_dir {params.yield_dir} \
        --output_csv {output.aggregated_csv} \
        --verbose > {log}
        """

rule aggregate_met_stats:
    input:
        met_files = expand(op.join(config['sim_study_head_dir'], '{{year}}', '{{timepoint}}', '{region}', '{region}_weather.met'), region=config['regions']),
        reference_tif_path = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'aggregated_yield_map_{}_{}_{}_{}.tif'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')),
    params:
        executable_fpath = config['scripts']['aggregate_met_stats'],
        year = lambda wildcards: wildcards.year,
        roi_base_dir = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}')
    log:
        'logs_aggregate_met_stats/{year}_{timepoint}.log'
    output:
        aggregated_met_stats_pdf = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'aggregated_met_stats_{}_{}_{}_{}.pdf'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')),
        aggregated_met_stats_tif = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'aggregated_met_stats_{}_{}_{}_{}.tif'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')),
    shell:
        """
        python {params.executable_fpath} \
        --regions_base_dir {params.roi_base_dir} \
        --year {params.year} \
        --output_pdf_path {output.aggregated_met_stats_pdf} \
        --reference_tif_path {input.reference_tif_path} \
        --output_tif_path {output.aggregated_met_stats_tif} \
        --verbose > {log}
        """

rule aggregate_maps:
    input:
        cropmasks = expand(op.join(config['sim_study_head_dir'], '{{year}}', '{{timepoint}}', '{region}', '{region}_cropmask_constrained.tif'), region=config['regions']),
        lai_maps = expand(op.join(config['sim_study_head_dir'], '{{year}}', '{{timepoint}}', '{region}', '{region}_LAI_MAX.tif'), region=config['regions']),
        yield_maps = expand(op.join(config['sim_study_head_dir'], '{{year}}', '{{timepoint}}', '{region}', '{region}_yield_map.tif'), region=config['regions']),
        aggregated_yield_estimates = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'aggregated_yield_estimates_{}_{}_{}_{}.csv'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')),
    params:
        executable_fpath = config['scripts']['aggregate_maps'],
        roi_base_dir = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}'),
        validation_cmd = f"--val_fpath {op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'groundtruth.csv')}" if op.exists(op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'groundtruth.csv')) else ''
    log:
        'logs_aggregate_maps/{year}_{timepoint}.log'
    output:
        aggregated_yield_map = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'aggregated_yield_map_{}_{}_{}_{}.tif'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')),
        aggregated_lai_map = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'aggregated_LAI_MAX_{}_{}_{}_{}.tif'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')),
        aggregated_cropmask = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'aggregated_cropmask_{}_{}_{}_{}.tif'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')),
        aggregated_shapefile = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'aggregated_region_boundaries_{}_{}_{}_{}.geojson'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')),
    shell:
        """
        python {params.executable_fpath} \
        --roi_base_dir {params.roi_base_dir} \
        {params.validation_cmd} \
        --yield_estimates_fpath {input.aggregated_yield_estimates} \
        --output_lai_tif_fpath {output.aggregated_lai_map} \
        --output_yield_tif_fpath {output.aggregated_yield_map} \
        --output_cropmask_tif_fpath {output.aggregated_cropmask} \
        --output_shapefile_fpath {output.aggregated_shapefile} > {log}
        """

rule evaluate_yield_estimates:
    input:
        aggregated_yield_estimates = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'aggregated_yield_estimates_{}_{}_{}_{}.csv'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')),
        validation_fpath = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'groundtruth.csv')
    params:
        executable_fpath = config['scripts']['evaluate_yield_estimates'],
    log:
        'logs_evaluate_yield_estimates/{year}_{timepoint}.log'
    output:
        evaluation_out_path = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'evaluation.csv')
    shell:
        """
        python {params.executable_fpath} \
        --val_fpath {input.validation_fpath} \
        --estimation_fpath {input.aggregated_yield_estimates} \
        --out_fpath {output.evaluation_out_path} > {log}
        """

rule generate_final_report:
    input:
        region_geojsons = expand(op.join(config['sim_study_head_dir'], '{{year}}', '{{timepoint}}', '{region}', '{region}.geojson'), region=config['regions']),
        aggregated_yield_estimates = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'aggregated_yield_estimates_{}_{}_{}_{}.csv'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')),
        aggregated_yield_map =  op.join(config['sim_study_head_dir'], '{year}', '{timepoint}', 'aggregated_yield_map_{}_{}_{}_{}.tif'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')),
        evaluation_results = get_evaluation_results_path_func(config)
    params:
        executable_fpath = config['scripts']['generate_final_report'],
        regions_dir = op.join(config['sim_study_head_dir'], '{year}', '{timepoint}'),
        start_date = lambda wildcards: config['apsim_params'][int(wildcards.year)][wildcards.timepoint]['sim_start_date'],
        end_date = lambda wildcards: config['apsim_params'][int(wildcards.year)][wildcards.timepoint]['sim_end_date'],
        evaluation_results_cmd = lambda _, input: f'--evaluation_results_path {input.evaluation_results}' if input.evaluation_results else '',
        validation_cmd = lambda wildcards, input: f"--val_fpath {op.join(config['sim_study_head_dir'], wildcards.year, wildcards.timepoint, 'groundtruth.csv')}" if input.evaluation_results else '',
        roi_name = config['roi_name'],
        crop_name = config['lai_params']['crop_name']
    log:
        'logs_generate_final_report/{year}_{timepoint}.log'
    output:
        report_fpath = op.join(config['sim_study_head_dir'], 
                               '{year}',
                               '{timepoint}', 
                               'final_report_{}_{}_{}_{}.pdf'.format(Path(config['sim_study_head_dir']).name, config['roi_name'], '{year}', '{timepoint}')), 
    shell:
        """
        python {params.executable_fpath} \
        --regions_dir {params.regions_dir} \
        --out_fpath {output.report_fpath} \
        --start_date {params.start_date} \
        --end_date {params.end_date} \
        --aggregated_yield_map_path {input.aggregated_yield_map} \
        --aggregated_yield_estimates_path {input.aggregated_yield_estimates} \
        {params.evaluation_results_cmd} \
        {params.validation_cmd} \
        --roi_name {params.roi_name} \
        --crop_name {params.crop_name} \
        --verbose > {log}
        """
